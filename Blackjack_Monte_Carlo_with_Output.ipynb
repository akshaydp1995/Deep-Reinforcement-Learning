{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blackjack - Monte Carlo with Output.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaydp1995/Deep-Reinforcement-Learning/blob/master/Blackjack_Monte_Carlo_with_Output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "3qyb6ES0xmov",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Libraries\n",
        "##### OpenAI's Gym toolkit has a lot of built-in environments"
      ]
    },
    {
      "metadata": {
        "id": "ZLtipjwtxmow",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lnhiG4Zqxmoz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the Blackjack Environment\n",
        "##### Print the State Space, Action Space, Reward Range, Discount Factor"
      ]
    },
    {
      "metadata": {
        "id": "58UPyaAYxmo0",
        "colab_type": "code",
        "outputId": "9e18ef1b-acff-4b87-f9fe-736bd36947e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Create an environment using OpenAI's Gym Toolkit\n",
        "\n",
        "env = gym.make('Blackjack-v0')   # Create an environment\n",
        "gamma = 0.9\n",
        "\n",
        "print(\"Observation Space  :\", env.observation_space)     # State Space\n",
        "print(\"Action Space       :\", env.action_space)          # Action Space\n",
        "print(\"Reward Range       :\", env.reward_range)          # Reward Range\n",
        "print(\"Discount Factor    :\", gamma)                     # Discount Factor"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation Space  : Tuple(Discrete(32), Discrete(11), Discrete(2))\n",
            "Action Space       : Discrete(2)\n",
            "Reward Range       : (-inf, inf)\n",
            "Discount Factor    : 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "85fuIVvJxmo6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate an episode - Equiprobable Random Policy\n",
        "##### Select an action with equal probability for any state \n",
        "##### Generating a single episode (state, action, reward)"
      ]
    },
    {
      "metadata": {
        "id": "TxA_ryyrxmo7",
        "colab_type": "code",
        "outputId": "28760b0d-f562-497e-dd1f-97413501674b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "## Episodic Task - Use Monte Carlo Method to create an episode\n",
        "\n",
        "def generate_episode_erp(): \n",
        "    episode = []\n",
        "    state = env.reset()\n",
        "    done = 0\n",
        "    while True:\n",
        "        probs = [0.5, 0.5]                                   # Policy\n",
        "        action = np.random.choice([0, 1], p = probs)\n",
        "        next_state, reward, done, info = env.step(action)    # Take an action\n",
        "        episode.append((state, action, reward))\n",
        "        state = next_state\n",
        "        if done == 1: \n",
        "            break\n",
        "    return episode\n",
        "\n",
        "generate_episode_erp()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((16, 9, False), 1, 0), ((21, 9, False), 0, 1.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "Q0K64patxmpA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate an episode - 'Policy number 1' (80% when sum > 18)\n",
        "##### Policy - Take an action \"Stick\" with 80% probability when sum of cards > 18 \n",
        "##### Generating a single episode (state, action, reward)"
      ]
    },
    {
      "metadata": {
        "id": "MyfmDb4FxmpC",
        "colab_type": "code",
        "outputId": "58896662-adda-452f-f59d-61d17d96e991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "## Episodic Task - Use Monte Carlo Method to create an episode\n",
        "\n",
        "def generate_episode_18(): \n",
        "    episode = []\n",
        "    state = env.reset()\n",
        "    done = 0\n",
        "    while True:\n",
        "        probs = [0.8, 0.2] if state[0] > 18 else [0.2, 0.8]  # Policy\n",
        "        action = np.random.choice([0, 1], p = probs)\n",
        "        next_state, reward, done, info = env.step(action)    # Take an action\n",
        "        episode.append((state, action, reward))\n",
        "        state = next_state\n",
        "        if done == 1: \n",
        "            break\n",
        "    return episode\n",
        "\n",
        "generate_episode_18()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((11, 7, False), 1, 0), ((21, 7, False), 0, 1.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-amYvOtI0ABu"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate an episode - for any policy Q (greedy policy)\n",
        "##### Input a policy Q \n",
        "##### Generating a single episode using the input policy Q "
      ]
    },
    {
      "metadata": {
        "id": "-gwusNZry4r3",
        "colab_type": "code",
        "outputId": "a6ceef20-7e03-4081-e206-a553e2473d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def generate_episode_fv_policy(Q): \n",
        "    episode = []\n",
        "    state = env.reset()\n",
        "    done = 0\n",
        "    while True:\n",
        "        prob = [0, 1] if np.argmax(Q[state])==1 else [1, 0]\n",
        "        action = np.random.choice([0, 1], p = prob)\n",
        "        next_state, reward, done, info = env.step(action)    # Take an action\n",
        "        episode.append((state, action, reward))\n",
        "        state = next_state\n",
        "        if done == 1: \n",
        "            break\n",
        "    return episode\n",
        "  \n",
        "Q = defaultdict(lambda: np.zeros(2))                         # Random policy to check if function works\n",
        "generate_episode_fv_policy(Q) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((20, 10, False), 0, 1.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "S0QVo91e1cdg"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate an episode - for any policy Q (epsilon-greedy policy)\n",
        "##### Input epsilon value\n",
        "##### probs() - Input is epsilon, Q and state - Output is the new action-value function for that particular state\n",
        "##### Generating an episode with a particular epsilon and a particular input policy Q"
      ]
    },
    {
      "metadata": {
        "id": "O3gzFfS-1fpk",
        "colab_type": "code",
        "outputId": "77d121d4-8681-4c93-c9b1-d547e82f2c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def probs(epsilon, Q, state): \n",
        "    maxx = np.argmax(Q[state])\n",
        "    Q[state] = [epsilon/2, epsilon/2]\n",
        "    Q[state][maxx] = 1 - epsilon + (epsilon/2)\n",
        "\n",
        "def generate_episode_fv_policy(epsilon, Q): \n",
        "    episode = []\n",
        "    state = env.reset()\n",
        "    done = 0\n",
        "    while True:\n",
        "        prob = probs(epsilon, Q, state)\n",
        "        action = np.random.choice([0, 1], p = prob)\n",
        "        next_state, reward, done, info = env.step(action)    # Take an action\n",
        "        episode.append((state, action, reward))\n",
        "        state = next_state\n",
        "        if done == 1: \n",
        "            break\n",
        "    return episode\n",
        "  \n",
        "Q = defaultdict(lambda: np.zeros(2))                         # Random policy to check if function works\n",
        "epsilon = 0.9  \n",
        "generate_episode_fv_policy(epsilon, Q)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((16, 10, False), 1, -1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "hAbDhaP6xmpF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fill the Q-table"
      ]
    },
    {
      "metadata": {
        "id": "otLxmL6j-Pm2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### First-visit prediction with equiprobable random policy"
      ]
    },
    {
      "metadata": {
        "id": "eSJFXYuMxmpG",
        "colab_type": "code",
        "outputId": "ce6bb957-cbf4-426d-b937-e8c20d923bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "# Function to evaluate policy using first-visit MC\n",
        "\n",
        "def policy_evaluation_fv_erp(number_episodes = 1): \n",
        "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    summ = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    N = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    for _ in range(number_episodes): \n",
        "        states, actions, rewards = zip(*generate_episode_erp())\n",
        "        states_all = []\n",
        "        for index, state in enumerate(states): \n",
        "            if state not in states_all: \n",
        "                summ[state][actions[index]] = sum([(gamma)**i for i in range(len(rewards))][::-1][::-1]*np.asarray(rewards))\n",
        "                N[state][actions[index]] += 1\n",
        "            Q[state][actions[index]] = summ[state][actions[index]] / N[state][actions[index]]\n",
        "            states_all.append(state)\n",
        "    return Q\n",
        "                \n",
        "policy_evaluation_fv_erp(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.policy_evaluation_fv_erp.<locals>.<lambda>>,\n",
              "            {(7, 10, False): array([ 0. , -0.9]),\n",
              "             (8, 10, False): array([0.  , 0.81]),\n",
              "             (10, 5, False): array([0. , 0.9]),\n",
              "             (10, 10, False): array([ 0. , -0.9]),\n",
              "             (13, 10, False): array([-1.,  0.]),\n",
              "             (14, 5, False): array([0.9, 0. ]),\n",
              "             (16, 2, False): array([-1.,  0.]),\n",
              "             (16, 10, False): array([-0.9 ,  0.81]),\n",
              "             (17, 6, False): array([ 0., -1.]),\n",
              "             (17, 10, False): array([ 0.9, -0.9]),\n",
              "             (17, 10, True): array([0. , 0.9]),\n",
              "             (18, 10, False): array([0.81, 0.  ]),\n",
              "             (19, 9, False): array([1., 0.]),\n",
              "             (20, 3, False): array([ 0., -1.])})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "SlULJ2ewxmpK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Every-visit prediction with equiprobable random policy"
      ]
    },
    {
      "metadata": {
        "id": "B0c1L92nxmpL",
        "colab_type": "code",
        "outputId": "062a293a-f5de-415e-aa35-ea74d9690613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Function to evaluate policy using every-visit MC\n",
        "\n",
        "def policy_evaluation_ev_erp(number_episodes = 1): \n",
        "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    summ = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    N = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    for _ in range(number_episodes): \n",
        "        states, actions, rewards = zip(*generate_episode_erp())\n",
        "        for index, state in enumerate(states): \n",
        "            summ[state][actions[index]] = sum([(gamma)**i for i in range(len(rewards))][::-1][::-1]*np.asarray(rewards))\n",
        "            N[state][actions[index]] += 1\n",
        "            Q[state][actions[index]] = summ[state][actions[index]] / N[state][actions[index]]\n",
        "    return Q\n",
        "                \n",
        "policy_evaluation_ev_erp(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.policy_evaluation_ev_erp.<locals>.<lambda>>,\n",
              "            {(7, 7, False): array([-1.,  0.]),\n",
              "             (8, 9, False): array([-1.,  0.]),\n",
              "             (9, 10, False): array([-1.,  0.]),\n",
              "             (14, 5, False): array([-1.,  0.]),\n",
              "             (15, 9, False): array([-1.,  0.]),\n",
              "             (15, 10, False): array([-1.,  0.]),\n",
              "             (18, 9, False): array([ 0., -1.]),\n",
              "             (20, 10, False): array([ 0., -1.]),\n",
              "             (21, 8, True): array([1., 0.]),\n",
              "             (21, 10, True): array([1., 0.])})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "vxzH5Rm6xmpO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### First-visit prediction with 'Policy number 1'"
      ]
    },
    {
      "metadata": {
        "id": "mrFoittYxmpP",
        "colab_type": "code",
        "outputId": "a389c163-e5f2-4938-f113-ddea697971aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Function to evaluate policy using first-visit MC\n",
        "\n",
        "def policy_evaluation_fv_18(number_episodes = 1): \n",
        "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    summ = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    N = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    for _ in range(number_episodes): \n",
        "        states, actions, rewards = zip(*generate_episode_erp())\n",
        "        states_all = []\n",
        "        for index, state in enumerate(states): \n",
        "            if state not in states_all: \n",
        "                summ[state][actions[index]] = sum([(gamma)**i for i in range(len(rewards))][::-1][::-1]*np.asarray(rewards))\n",
        "                N[state][actions[index]] += 1\n",
        "            Q[state][actions[index]] = summ[state][actions[index]] / N[state][actions[index]]\n",
        "            states_all.append(state)\n",
        "    return Q\n",
        "                \n",
        "policy_evaluation_fv_18(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.policy_evaluation_fv_18.<locals>.<lambda>>,\n",
              "            {(9, 9, False): array([-1.,  0.]),\n",
              "             (12, 4, False): array([1., 0.]),\n",
              "             (12, 10, True): array([-1.,  0.]),\n",
              "             (13, 1, False): array([-1.,  0.]),\n",
              "             (13, 7, False): array([1., 0.]),\n",
              "             (13, 10, False): array([1., 0.]),\n",
              "             (14, 7, False): array([1., 0.]),\n",
              "             (15, 3, False): array([ 0., -1.]),\n",
              "             (15, 9, True): array([1., 0.]),\n",
              "             (19, 6, False): array([1., 0.])})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "D_u-jy9kxmpT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Every-visit prediction with 'Policy number 1'"
      ]
    },
    {
      "metadata": {
        "id": "o6PuULP5xmpT",
        "colab_type": "code",
        "outputId": "a8d37455-2f5e-46ac-82ad-d7b27d0a43b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "# Function to evaluate policy using every-visit MC\n",
        "\n",
        "def policy_evaluation_ev_18(number_episodes = 1): \n",
        "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    summ = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    N = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    for _ in range(number_episodes): \n",
        "        states, actions, rewards = zip(*generate_episode_erp())\n",
        "        for index, state in enumerate(states): \n",
        "            summ[state][actions[index]] = sum([(gamma)**i for i in range(len(rewards))][::-1][::-1]*np.asarray(rewards))\n",
        "            N[state][actions[index]] += 1\n",
        "            Q[state][actions[index]] = summ[state][actions[index]] / N[state][actions[index]]\n",
        "    return Q\n",
        "                \n",
        "policy_evaluation_ev_18(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.policy_evaluation_ev_18.<locals>.<lambda>>,\n",
              "            {(8, 9, False): array([-1.,  0.]),\n",
              "             (9, 10, False): array([ 0. , -0.9]),\n",
              "             (10, 10, False): array([ 0. , -0.9]),\n",
              "             (12, 1, False): array([ 0.  , -0.81]),\n",
              "             (12, 3, True): array([-1.,  0.]),\n",
              "             (13, 9, False): array([ 0., -1.]),\n",
              "             (14, 10, False): array([-1.,  0.]),\n",
              "             (15, 10, False): array([-1.,  0.]),\n",
              "             (16, 10, False): array([-1.,  0.]),\n",
              "             (19, 1, False): array([ 0.  , -0.81]),\n",
              "             (19, 10, False): array([ 0.  , -0.45]),\n",
              "             (20, 1, False): array([ 0.  , -0.81]),\n",
              "             (21, 3, True): array([1., 0.])})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "bDQ5YET96L6r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### First-visit prediction for any policy - several episodes for the same policy to converge to actual action-value function"
      ]
    },
    {
      "metadata": {
        "id": "nFhUd2af6MTT",
        "colab_type": "code",
        "outputId": "304f154d-6268-46c9-c7dc-ee3ac57e885c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "# Function to evaluate policy using first-visit MC\n",
        "\n",
        "def policy_evaluation_fv_policy(epsilon, Q, number_episodes = 1): \n",
        "    summ = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    N = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    for _ in range(number_episodes): \n",
        "        states, actions, rewards = zip(*generate_episode_fv_policy(epsilon, Q))\n",
        "        states_all = []\n",
        "        for index, state in enumerate(states): \n",
        "            if state not in states_all: \n",
        "                summ[state][actions[index]] = sum([(gamma)**i for i in range(len(rewards))][::-1][::-1]*np.asarray(rewards))\n",
        "                N[state][actions[index]] += 1\n",
        "            Q[state][actions[index]] = summ[state][actions[index]] / N[state][actions[index]]\n",
        "            states_all.append(state)\n",
        "    return Q\n",
        "  \n",
        "Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "epsilon = 0.9  \n",
        "policy_evaluation_fv_policy(epsilon, Q, 10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>>,\n",
              "            {(6, 10, False): [-1.0, 0.45],\n",
              "             (8, 9, False): [1.0, 0.45],\n",
              "             (9, 4, False): [-1.0, 0.45],\n",
              "             (11, 10, False): [-1.0, 0.45],\n",
              "             (13, 6, False): [0.55, 0.9],\n",
              "             (14, 9, False): [0.55, 0.9],\n",
              "             (15, 10, False): [-1.0, 0.45],\n",
              "             (16, 6, False): [0.9, 0.45],\n",
              "             (18, 4, False): [0.55, 0.9],\n",
              "             (18, 9, False): [0.9, 0.45],\n",
              "             (19, 3, False): [-1.0, 0.45],\n",
              "             (19, 4, False): [0.9, 0.45],\n",
              "             (20, 5, False): [1.0, 0.45]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "SBP5vicu6MrJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Every-visit prediction for any policy"
      ]
    },
    {
      "metadata": {
        "id": "G2hbLnhv6M2o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to evaluate policy using every-visit MC\n",
        "\n",
        "def policy_evaluation_ev_policy(epsilon, number_episodes = 1): \n",
        "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    summ = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    N = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    for _ in range(number_episodes): \n",
        "        states, actions, rewards = zip(*generate_episode_fv_policy(epsilon, Q))\n",
        "        for index, state in enumerate(states): \n",
        "            summ[state][actions[index]] = sum([(gamma)**i for i in range(len(rewards))][::-1][::-1]*np.asarray(rewards))\n",
        "            N[state][actions[index]] += 1\n",
        "            Q[state][actions[index]] = summ[state][actions[index]] / N[state][actions[index]]\n",
        "    return Q\n",
        "  \n",
        "epsilon = 0.9                 \n",
        "# policy_evaluation_fv_policy(epsilon, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kUFQmGnTxmpb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Monte Carlo Control Method\n",
        "##### Converging to optimal policy using the epsilon-greedy policy - First-visit prediction"
      ]
    },
    {
      "metadata": {
        "id": "uufLqCGC9Ovl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def update_Q(episode, Q, alpha, gamma):\n",
        "    states, actions, rewards = zip(*episode)\n",
        "    for i, state in enumerate(states):\n",
        "        old_Q = Q[state][actions[i]] \n",
        "        Q[state][actions[i]] = old_Q + alpha*(sum([(gamma)**i for i in range(len(rewards))][::-1][::-1]*np.asarray(rewards)) - old_Q)\n",
        "    return Q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TILfUrPRxmpd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def goal(alpha, epsilon, epochs): \n",
        "    Q = defaultdict(lambda: np.zeros(2))\n",
        "    for _ in range(epochs):\n",
        "        eps = max(epsilon - _*0.0001, 0.1)\n",
        "        episode = generate_episode_fv_policy(eps, Q)\n",
        "        Q = update_Q(episode, Q, alpha, gamma)\n",
        "    policy = dict((k,np.argmax(v)) for k, v in Q.items())\n",
        "    return policy, Q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kS3MGOvW0hVb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Code for plotting the output"
      ]
    },
    {
      "metadata": {
        "id": "nOcszGc_0bTI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "def plot_blackjack_values(V):\n",
        "\n",
        "    def get_Z(x, y, usable_ace):\n",
        "        if (x,y,usable_ace) in V:\n",
        "            return V[x,y,usable_ace]\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def get_figure(usable_ace, ax):\n",
        "        x_range = np.arange(11, 22)\n",
        "        y_range = np.arange(1, 11)\n",
        "        X, Y = np.meshgrid(x_range, y_range)\n",
        "        \n",
        "        Z = np.array([get_Z(x,y,usable_ace) for x,y in zip(np.ravel(X), np.ravel(Y))]).reshape(X.shape)\n",
        "\n",
        "        surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=plt.cm.coolwarm, vmin=-1.0, vmax=1.0)\n",
        "        ax.set_xlabel('Player\\'s Current Sum')\n",
        "        ax.set_ylabel('Dealer\\'s Showing Card')\n",
        "        ax.set_zlabel('State Value')\n",
        "        ax.view_init(ax.elev, -120)\n",
        "\n",
        "    fig = plt.figure(figsize=(20, 20))\n",
        "    ax = fig.add_subplot(211, projection='3d')\n",
        "    ax.set_title('Usable Ace')\n",
        "    get_figure(True, ax)\n",
        "    ax = fig.add_subplot(212, projection='3d')\n",
        "    ax.set_title('No Usable Ace')\n",
        "    get_figure(False, ax)\n",
        "    plt.show()\n",
        "\n",
        "def plot_policy(policy):\n",
        "\n",
        "    def get_Z(x, y, usable_ace):\n",
        "        if (x,y,usable_ace) in policy:\n",
        "            return policy[x,y,usable_ace]\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "    def get_figure(usable_ace, ax):\n",
        "        x_range = np.arange(11, 22)\n",
        "        y_range = np.arange(10, 0, -1)\n",
        "        X, Y = np.meshgrid(x_range, y_range)\n",
        "        Z = np.array([[get_Z(x,y,usable_ace) for x in x_range] for y in y_range])\n",
        "        surf = ax.imshow(Z, cmap=plt.get_cmap('Pastel2', 2), vmin=0, vmax=1, extent=[10.5, 21.5, 0.5, 10.5])\n",
        "        plt.xticks(x_range)\n",
        "        plt.yticks(y_range)\n",
        "        plt.gca().invert_yaxis()\n",
        "        ax.set_xlabel('Player\\'s Current Sum')\n",
        "        ax.set_ylabel('Dealer\\'s Showing Card')\n",
        "        ax.grid(color='w', linestyle='-', linewidth=1)\n",
        "        divider = make_axes_locatable(ax)\n",
        "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
        "        cbar = plt.colorbar(surf, ticks=[0,1], cax=cax)\n",
        "        cbar.ax.set_yticklabels(['0 (STICK)','1 (HIT)'])\n",
        "            \n",
        "    fig = plt.figure(figsize=(15, 15))\n",
        "    ax = fig.add_subplot(121)\n",
        "    ax.set_title('Usable Ace')\n",
        "    get_figure(True, ax)\n",
        "    ax = fig.add_subplot(122)\n",
        "    ax.set_title('No Usable Ace')\n",
        "    get_figure(False, ax)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZlHQYmC_wIl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plotting the Output"
      ]
    },
    {
      "metadata": {
        "id": "zptBqyBzxmph",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "policy, Q = goal(0.31, 0.9, 500000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BzVgFXnTM_NF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "11ad7abc-ab0e-4059-87da-8b9a3bfba549"
      },
      "cell_type": "code",
      "source": [
        "plot_policy(policy)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6cAAAF/CAYAAAC17r8bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyn0HSFAuQZVaNbEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}