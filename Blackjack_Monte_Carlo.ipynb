{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Monte_Carlo_Solution (2).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaydp1995/Deep-Reinforcement-Learning/blob/master/Blackjack_Monte_Carlo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "3qyb6ES0xmov",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "metadata": {
        "id": "ZLtipjwtxmow",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import plot_utils\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lnhiG4Zqxmoz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the Blackjack Environment\n",
        "##### Print the State Space, Action Space, Reward Range, Discount Factor"
      ]
    },
    {
      "metadata": {
        "id": "58UPyaAYxmo0",
        "colab_type": "code",
        "colab": {},
        "outputId": "ceb17f9c-4758-4aa3-d103-2f96fe8a6424"
      },
      "cell_type": "code",
      "source": [
        "# Create an environment using OpenAI's Gym Toolkit\n",
        "\n",
        "env = gym.make('Blackjack-v0')   # Create an environment\n",
        "gamma = 0.9\n",
        "\n",
        "print(\"Observation Space  :\", env.observation_space)     # State Space\n",
        "print(\"Action Space       :\", env.action_space)          # Action Space\n",
        "print(\"Reward Range       :\", env.reward_range)          # Reward Range\n",
        "print(\"Discount Factor    :\", gamma)                     # Discount Factor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation Space  : Tuple(Discrete(32), Discrete(11), Discrete(2))\n",
            "Action Space       : Discrete(2)\n",
            "Reward Range       : (-inf, inf)\n",
            "Discount Factor    : 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "85fuIVvJxmo6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate an episode - Equiprobable Random Policy\n",
        "##### Select an action with equal probability for any state"
      ]
    },
    {
      "metadata": {
        "id": "TxA_ryyrxmo7",
        "colab_type": "code",
        "colab": {},
        "outputId": "8b27909f-96c2-46dc-d64f-07927220b376"
      },
      "cell_type": "code",
      "source": [
        "## Episodic Task - Use Monte Carlo Method to create an episode\n",
        "\n",
        "def generate_episode_erp(): \n",
        "    episode = []\n",
        "    state = env.reset()\n",
        "    done = 0\n",
        "    while True:\n",
        "        probs = [0.5, 0.5]                                   # Policy\n",
        "        action = np.random.choice([0, 1], p = probs)\n",
        "        next_state, reward, done, info = env.step(action)    # Take an action\n",
        "        episode.append((state, action, reward))\n",
        "        state = next_state\n",
        "        if done == 1: \n",
        "            break\n",
        "    return episode\n",
        "\n",
        "generate_episode_erp()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((12, 5, False), 1, -1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "Q0K64patxmpA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate Episode - Policy \n",
        "##### Policy - Take an action \"Stick\" with 80% probability when sum of cards > 18 - Denote this as 'Policy Number 1'"
      ]
    },
    {
      "metadata": {
        "id": "MyfmDb4FxmpC",
        "colab_type": "code",
        "colab": {},
        "outputId": "a88051ac-94ff-450b-8216-a7b575c04394"
      },
      "cell_type": "code",
      "source": [
        "## Episodic Task - Use Monte Carlo Method to create an episode\n",
        "\n",
        "def generate_episode_18(): \n",
        "    episode = []\n",
        "    state = env.reset()\n",
        "    done = 0\n",
        "    while True:\n",
        "        probs = [0.8, 0.2] if state[0] > 18 else [0.2, 0.8]  # Policy\n",
        "        action = np.random.choice([0, 1], p = probs)\n",
        "        next_state, reward, done, info = env.step(action)    # Take an action\n",
        "        episode.append((state, action, reward))\n",
        "        state = next_state\n",
        "        if done == 1: \n",
        "            break\n",
        "    return episode\n",
        "\n",
        "generate_episode_18()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((15, 6, False), 1, -1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "hAbDhaP6xmpF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fill the Q-table\n",
        "##### First-visit prediction with equiprobable random policy"
      ]
    },
    {
      "metadata": {
        "id": "eSJFXYuMxmpG",
        "colab_type": "code",
        "colab": {},
        "outputId": "a5aff3d5-79a4-47ab-8ac1-adf07dae571b"
      },
      "cell_type": "code",
      "source": [
        "# Function to evaluate policy using first-visit MC\n",
        "\n",
        "def policy_evaluation_fv_erp(number_episodes = 1): \n",
        "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    summ = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    N = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    for _ in range(number_episodes): \n",
        "        states, actions, rewards = zip(*generate_episode_erp())\n",
        "        states_all = []\n",
        "        for index, state in enumerate(states): \n",
        "            if state not in states_all: \n",
        "                summ[state][actions[index]] = sum([(gamma)**i for i in range(len(rewards))][::-1][::-1]*np.asarray(rewards))\n",
        "                N[state][actions[index]] += 1\n",
        "            Q[state][actions[index]] = summ[state][actions[index]] / N[state][actions[index]]\n",
        "            states_all.append(state)\n",
        "    return Q\n",
        "                \n",
        "policy_evaluation_fv_erp(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.policy_evaluation_fv_erp.<locals>.<lambda>()>,\n",
              "            {(21, 6, True): array([ 0.   ,  0.405]),\n",
              "             (20, 6, False): array([ 0.,  0.]),\n",
              "             (16, 10, False): array([ 1.,  0.]),\n",
              "             (11, 5, False): array([-1.,  0.]),\n",
              "             (9, 8, False): array([ 0. ,  0.9]),\n",
              "             (19, 8, False): array([ 0.9,  0. ]),\n",
              "             (18, 5, False): array([ 0., -1.]),\n",
              "             (13, 2, False): array([ 0.  , -0.81]),\n",
              "             (16, 2, False): array([ 0.  , -0.81]),\n",
              "             (17, 2, False): array([-0.81,  0.  ]),\n",
              "             (10, 7, False): array([ 0. , -0.9]),\n",
              "             (16, 7, False): array([ 0. , -0.9]),\n",
              "             (14, 6, False): array([ 0.  ,  0.81]),\n",
              "             (18, 6, False): array([ 0.81,  0.  ]),\n",
              "             (9, 5, False): array([ 1.,  0.]),\n",
              "             (13, 9, True): array([-1.,  0.])})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "SlULJ2ewxmpK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Every-visit prediction with equiprobable random policy"
      ]
    },
    {
      "metadata": {
        "id": "B0c1L92nxmpL",
        "colab_type": "code",
        "colab": {},
        "outputId": "7d783a6b-80c3-4f2a-c8c8-65dacb7b4c42"
      },
      "cell_type": "code",
      "source": [
        "# Function to evaluate policy using every-visit MC\n",
        "\n",
        "def policy_evaluation_ev_erp(number_episodes = 1): \n",
        "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    summ = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    N = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    for _ in range(number_episodes): \n",
        "        states, actions, rewards = zip(*generate_episode_erp())\n",
        "        for index, state in enumerate(states): \n",
        "            summ[state][actions[index]] = sum([(gamma)**i for i in range(len(rewards))][::-1][::-1]*np.asarray(rewards))\n",
        "            N[state][actions[index]] += 1\n",
        "            Q[state][actions[index]] = summ[state][actions[index]] / N[state][actions[index]]\n",
        "    return Q\n",
        "                \n",
        "policy_evaluation_ev_erp(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.policy_evaluation_ev_erp.<locals>.<lambda>()>,\n",
              "            {(16, 10, False): array([ 0., -1.]),\n",
              "             (20, 2, False): array([ 0., -1.]),\n",
              "             (13, 1, False): array([-1.,  0.]),\n",
              "             (14, 10, False): array([ 1.,  0.]),\n",
              "             (12, 10, False): array([ 1.,  0.]),\n",
              "             (17, 5, True): array([-1.,  0.]),\n",
              "             (10, 7, False): array([ 0. , -0.9]),\n",
              "             (12, 7, False): array([-0.9,  0. ]),\n",
              "             (10, 6, False): array([ 1.,  0.]),\n",
              "             (18, 10, False): array([ 1.,  0.]),\n",
              "             (10, 9, False): array([ 1.,  0.])})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "vxzH5Rm6xmpO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### First-visit prediction with 'Policy number 1'"
      ]
    },
    {
      "metadata": {
        "id": "mrFoittYxmpP",
        "colab_type": "code",
        "colab": {},
        "outputId": "1875e596-fd51-4af4-97d2-9e7d88897178"
      },
      "cell_type": "code",
      "source": [
        "# Function to evaluate policy using first-visit MC\n",
        "\n",
        "def policy_evaluation_fv_18(number_episodes = 1): \n",
        "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    summ = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    N = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    for _ in range(number_episodes): \n",
        "        states, actions, rewards = zip(*generate_episode_erp())\n",
        "        states_all = []\n",
        "        for index, state in enumerate(states): \n",
        "            if state not in states_all: \n",
        "                summ[state][actions[index]] = sum([(gamma)**i for i in range(len(rewards))][::-1][::-1]*np.asarray(rewards))\n",
        "                N[state][actions[index]] += 1\n",
        "            Q[state][actions[index]] = summ[state][actions[index]] / N[state][actions[index]]\n",
        "            states_all.append(state)\n",
        "    return Q\n",
        "                \n",
        "policy_evaluation_fv_18(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.policy_evaluation_fv_18.<locals>.<lambda>()>,\n",
              "            {(11, 1, False): array([ 0.  , -0.81]),\n",
              "             (19, 1, False): array([ 0.  , -0.81]),\n",
              "             (20, 1, False): array([ 0.  , -0.81]),\n",
              "             (20, 10, False): array([ 1.,  0.]),\n",
              "             (14, 10, False): array([ 1.,  0.]),\n",
              "             (15, 8, False): array([ 0. , -0.9]),\n",
              "             (19, 8, False): array([ 0. , -0.9]),\n",
              "             (19, 6, False): array([ 0., -1.]),\n",
              "             (11, 10, False): array([ 0. ,  0.9]),\n",
              "             (17, 10, False): array([ 0.9,  0. ]),\n",
              "             (16, 1, True): array([ 1.,  0.]),\n",
              "             (5, 3, False): array([ 0. , -0.9]),\n",
              "             (15, 3, False): array([ 0. , -0.9]),\n",
              "             (4, 9, False): array([-1.,  0.]),\n",
              "             (15, 4, False): array([-1.,  0.])})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "D_u-jy9kxmpT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Every-visit prediction with equiprobable random policy"
      ]
    },
    {
      "metadata": {
        "id": "o6PuULP5xmpT",
        "colab_type": "code",
        "colab": {},
        "outputId": "46c34305-e2e9-4427-8ee5-292cebfc81c0"
      },
      "cell_type": "code",
      "source": [
        "# Function to evaluate policy using every-visit MC\n",
        "\n",
        "def policy_evaluation_ev_18(number_episodes = 1): \n",
        "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    summ = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    N = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    for _ in range(number_episodes): \n",
        "        states, actions, rewards = zip(*generate_episode_erp())\n",
        "        for index, state in enumerate(states): \n",
        "            summ[state][actions[index]] = sum([(gamma)**i for i in range(len(rewards))][::-1][::-1]*np.asarray(rewards))\n",
        "            N[state][actions[index]] += 1\n",
        "            Q[state][actions[index]] = summ[state][actions[index]] / N[state][actions[index]]\n",
        "    return Q\n",
        "                \n",
        "policy_evaluation_ev_18(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.policy_evaluation_ev_18.<locals>.<lambda>()>,\n",
              "            {(9, 10, False): array([-0.5,  0. ]),\n",
              "             (16, 5, True): array([ 1.,  0.]),\n",
              "             (15, 5, False): array([ 1.,  0.]),\n",
              "             (6, 3, False): array([-1.,  0.]),\n",
              "             (16, 3, False): array([ 0. , -0.9]),\n",
              "             (18, 3, False): array([ 0. , -0.9]),\n",
              "             (18, 5, False): array([ 0., -1.]),\n",
              "             (16, 1, True): array([-1.,  0.]),\n",
              "             (8, 10, False): array([ 1.,  0.]),\n",
              "             (19, 10, False): array([-1.,  0.])})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "kUFQmGnTxmpb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Monte Carlo Control Method\n",
        "##### Converging to optimal policy using the greedy policy - Starting with 'Policy number 1' with first-visit prediction method"
      ]
    },
    {
      "metadata": {
        "id": "TILfUrPRxmpd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def greedy(epochs = 100, episodes = 1200): \n",
        "    for _ in range(epochs): \n",
        "        Q = policy_evaluation_fv_18(episodes)\n",
        "        for key, value in Q.items(): \n",
        "            Q[key] = np.array([0, 1]) if np.argmax(value)==1 else np.array([1, 0]) \n",
        "    return Q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zptBqyBzxmph",
        "colab_type": "code",
        "colab": {},
        "outputId": "7c7f4d06-5da6-453f-f6eb-8c30b7dcd4f1"
      },
      "cell_type": "code",
      "source": [
        "optimal_Q = greedy()\n",
        "policy = dict((k,np.argmax(v)) for k, v in optimal_Q.items())\n",
        "plot_utils.plot_policy(policy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3f7203ecc0>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}